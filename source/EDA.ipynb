{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Exploratory Data analysis (EDA) on the data file.\n",
    "The steps would involve:\n",
    "\n",
    "    1. Import Libraries and Load the Data\n",
    "    2. Inspect the Data\n",
    "    3. Handle Missing Values\n",
    "    4. Check for Duplicate Rows\n",
    "    5. Data Visualization\n",
    "    6. Outlier Detection\n",
    "    7. Feature Engineering\n",
    "    8. Time Series Data\n",
    "    9. Save the Cleaned Data\n",
    "    10. Summarize the findings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About Data:\n",
    "Data is acquired from survey, Ideally it has 222 columns more comments on the columns are documented on the Excel sheet.\n",
    "the idea is to understand the possible deciding factors that makes IBT to decide to quit their current IBT position to nonIBT position.\n",
    "the current paper has proven its hyothesis using COR and CH framework using :structural equation modeling (SEM) and latent moder-\n",
    "ated structural equation modeling (LMS)\n",
    "\n",
    "understanding on how to convert this set up to ML suitable model and prove/disprove hypothesis is the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_data=pd.read_csv('wavedata.csv', encoding='utf-8') #fails due to mismatched encoding\n",
    "# file_data = pd.read_csv('wavedata.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Latin-1 (ISO-8859-1) encoding for data.\n",
    "Use Latin-1 for comments if:\n",
    "\n",
    "Your dataset is limited to Western European characters.\n",
    "You are working with legacy systems or need compatibility with older databases.\n",
    "Performance or memory efficiency is critical.\n",
    "For modern and scalable solutions, however, UTF-8 is generally recommended.\n",
    "\n",
    "But as the document follows the standard of Latin-1 or 'encoding': 'ISO-8859-1' hence this will be default for the project, henceforth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating the encoding after utf-8 failed.\n",
    "!pip install chardet\n",
    "\n",
    "import chardet\n",
    "\n",
    "# Detect encoding\n",
    "with open('wavedata.csv', 'rb') as file:\n",
    "    result = chardet.detect(file.read())\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result from the above code for documentation:\n",
    "{'encoding': 'ISO-8859-1', 'confidence': 0.73, 'language': ''}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 1: Import Libraries and Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   travfreq  aircrew  empl  jobsat1  jobsat2  jobsat3  roleover1  roleover2  \\\n",
      "0         3      2.0     1        4        4        4          3          4   \n",
      "1         3      2.0     1        4        4        5          4          4   \n",
      "2         3      2.0     1        4        3        3          4          4   \n",
      "3         3      2.0     1        4        4        4          2          3   \n",
      "4         4      2.0     1        4        4        4          3          4   \n",
      "\n",
      "   roleover3  workadj1  ...  yearstravel  numbertravel  daysknowtravel  \\\n",
      "0          4         5  ...          1.0             1              10   \n",
      "1          4         5  ...          1.0             3              14   \n",
      "2          4         4  ...          3.0             1              30   \n",
      "3          4         4  ...          5.0             1              15   \n",
      "4          3         4  ...         15.0             1              14   \n",
      "\n",
      "   meettravel  flytravel   countrytravel  daystrip  reasontrip  \\\n",
      "0           2          1          Europe       5.0           4   \n",
      "1           4          2  europe, france       4.0           1   \n",
      "2           5          2          Europe       5.0           6   \n",
      "3           3          2         Ireland       5.0           2   \n",
      "4           5          2           china      14.0           2   \n",
      "\n",
      "          otherreasontrip  weekendtrip  \n",
      "0                     NaN            1  \n",
      "1                     NaN            2  \n",
      "2  Meeting with Collegues            3  \n",
      "3                     NaN            1  \n",
      "4                     NaN            3  \n",
      "\n",
      "[5 rows x 222 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the CSV file with the detected encoding\n",
    "df = pd.read_csv('wavedata.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Display the data to verify it loads correctly\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['travfreq', 'aircrew', 'empl', 'jobsat1', 'jobsat2', 'jobsat3', 'roleover1', 'roleover2', 'roleover3', 'workadj1', 'workadj2', 'workadj3', 'workadj4', 'workadj5', 'workadj6', 'workadj7', 'workadj8', 'workadj9', 'turnover1', 'turnover2', 'turnover3', 'wneglect1', 'wneglect2', 'wneglect3', 'wneglect4', 'wneglect5', 'wneglect6', 'wsitcon1', 'wsitcon2', 'wsitcon3', 'wsitcon4', 'wrclar1', 'wrclar2', 'wrclar3', 'wrclar4', 'wrclar5', 'wrclar6', 'wtimepres1', 'wtimepres2', 'wtimepres3', 'wtimepres4', 'wnovel1', 'wnovel2', 'wnovel3', 'wnovel4', 'wcowinsexphelp 1', 'wcowinsexphelp 2', 'wcowinsexphelp 3', 'wcowinsexphelp 4', 'wroleconflict 1', 'wroleconflict 2', 'wroleconflict 3', 'wintconflictd 1', 'wintconflictd 2', 'wintconflictd 3', 'wintconflictd 4', 'wintconflictf 1', 'wintconflictf 2', 'wintconflictf 3', 'wemotdem 1', 'wemotdem 2', 'wemotdem 3', 'wemotdem 4', 'wemotdem 5', 'wpeopresp1', 'wpeopresp2', 'wpeopresp3', 'wpeopresp4', 'wpeopresp5', 'wallcowexp1', 'wallcowexp2', 'wallcowexp3', 'wallcowexp4', 'wallcowexp5', 'wallcowexp6', 'wallcowexp7', 'wallcowexp8', 'wallcowexp9', 'wallcowexp10', 'wallcowexp11', 'wallcowexp12', 'cowint', 'cowdep', 'wteams', 'wcom', 'Unnamed: 85', 'fsat1', 'fsat2', 'fsat3', 'fneglect1', 'fneglect2', 'fneglect3', 'fneglect4', 'fneglect5', 'fneglect6', 'fadj1', 'fadj2', 'fadj3', 'fadj4', 'fadj5', 'fadj6', 'fadj7', 'fadj8', 'fadj9', 'wfc1', 'wfc2', 'wfc3', 'wfc4', 'wfc5', 'ftimepres1', 'ftimepres2', 'ftimepres3', 'ftimepres4', 'check2', 'faminstexp1', 'faminstexp2', 'faminstexp3', 'faminstexp4', 'femotdem1', 'femotdem2', 'femotdem3', 'femotdem4', 'froleover1', 'froleover2', 'froleover3', 'froleconf1', 'froleconf2', 'froleconf3', 'fintconfd1', 'fintconfd2', 'fintconfd3', 'fintconfd4', 'fintconff1', 'fintconff2', 'fintconff3', 'famallexp1', 'famallexp2', 'famallexp3', 'famallexp4', 'famallexp5', 'famallexp6', 'famallexp7', 'famallexp8', 'famallexp9', 'famallexp10', 'famallexp11', 'famallexp12', 'burn1', 'burn2', 'burn3', 'burn4', 'burn5', 'burn6', 'burn7', 'burn8', 'burn9', 'burn10', 'burn11', 'burn12', 'burn13', 'burn14', 'burn15', 'burn16', 'burn17', 'burn18', 'burn19', 'burn20', 'burn21', 'supsup1', 'cowsup1', 'parsup1', 'famsup1', 'supsup2', 'cowsup2', 'parsup2', 'famsup2', 'supsup3', 'cowsup3', 'parsup3', 'famsup3', 'supsup4', 'cowsup4', 'parsup4', 'famsup4', 'cogflex1', 'cogflex2', 'cogflex3', 'cogflex4', 'cogflex5', 'cogflex6', 'cogflex7', 'cogflex8', 'cogflex9', 'cogflex10', 'cogflex11', 'cogflex12', 'houswork', 'childwork', 'marstat', 'children', 'whours', 'tenure', 'position', 'education', 'gender', 'age', 'industry', 'otherindustry', 'nationality', 'residence', 'lang', 'feeltravel', 'yearstravel', 'numbertravel', 'daysknowtravel', 'meettravel', 'flytravel', 'countrytravel', 'daystrip', 'reasontrip', 'otherreasontrip', 'weekendtrip']\n",
      "travfreq           579\n",
      "aircrew            524\n",
      "empl               579\n",
      "jobsat1            579\n",
      "jobsat2            579\n",
      "                  ... \n",
      "countrytravel      578\n",
      "daystrip           577\n",
      "reasontrip         579\n",
      "otherreasontrip     38\n",
      "weekendtrip        579\n",
      "Length: 222, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print((df.columns).to_list())\n",
    "column_count=(df.columns).to_list()\n",
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222\n"
     ]
    }
   ],
   "source": [
    "a=['travfreq', 'aircrew', 'empl', 'jobsat1', 'jobsat2', 'jobsat3', 'roleover1', 'roleover2', 'roleover3', 'workadj1', 'workadj2', 'workadj3', 'workadj4', 'workadj5', 'workadj6', 'workadj7', 'workadj8', 'workadj9', 'turnover1', 'turnover2', 'turnover3', 'wneglect1', 'wneglect2', 'wneglect3', 'wneglect4', 'wneglect5', 'wneglect6', 'wsitcon1', 'wsitcon2', 'wsitcon3', 'wsitcon4', 'wrclar1', 'wrclar2', 'wrclar3', 'wrclar4', 'wrclar5', 'wrclar6', 'wtimepres1', 'wtimepres2', 'wtimepres3', 'wtimepres4', 'wnovel1', 'wnovel2', 'wnovel3', 'wnovel4', 'wcowinsexphelp 1', 'wcowinsexphelp 2', 'wcowinsexphelp 3', 'wcowinsexphelp 4', 'wroleconflict 1', 'wroleconflict 2', 'wroleconflict 3', 'wintconflictd 1', 'wintconflictd 2', 'wintconflictd 3', 'wintconflictd 4', 'wintconflictf 1', 'wintconflictf 2', 'wintconflictf 3', 'wemotdem 1', 'wemotdem 2', 'wemotdem 3', 'wemotdem 4', 'wemotdem 5', 'wpeopresp1', 'wpeopresp2', 'wpeopresp3', 'wpeopresp4', 'wpeopresp5', 'wallcowexp1', 'wallcowexp2', 'wallcowexp3', 'wallcowexp4', 'wallcowexp5', 'wallcowexp6', 'wallcowexp7', 'wallcowexp8', 'wallcowexp9', 'wallcowexp10', 'wallcowexp11', 'wallcowexp12', 'cowint', 'cowdep', 'wteams', 'wcom', 'Unnamed: 85', 'fsat1', 'fsat2', 'fsat3', 'fneglect1', 'fneglect2', 'fneglect3', 'fneglect4', 'fneglect5', 'fneglect6', 'fadj1', 'fadj2', 'fadj3', 'fadj4', 'fadj5', 'fadj6', 'fadj7', 'fadj8', 'fadj9', 'wfc1', 'wfc2', 'wfc3', 'wfc4', 'wfc5', 'ftimepres1', 'ftimepres2', 'ftimepres3', 'ftimepres4', 'check2', 'faminstexp1', 'faminstexp2', 'faminstexp3', 'faminstexp4', 'femotdem1', 'femotdem2', 'femotdem3', 'femotdem4', 'froleover1', 'froleover2', 'froleover3', 'froleconf1', 'froleconf2', 'froleconf3', 'fintconfd1', 'fintconfd2', 'fintconfd3', 'fintconfd4', 'fintconff1', 'fintconff2', 'fintconff3', 'famallexp1', 'famallexp2', 'famallexp3', 'famallexp4', 'famallexp5', 'famallexp6', 'famallexp7', 'famallexp8', 'famallexp9', 'famallexp10', 'famallexp11', 'famallexp12', 'burn1', 'burn2', 'burn3', 'burn4', 'burn5', 'burn6', 'burn7', 'burn8', 'burn9', 'burn10', 'burn11', 'burn12', 'burn13', 'burn14', 'burn15', 'burn16', 'burn17', 'burn18', 'burn19', 'burn20', 'burn21', 'supsup1', 'cowsup1', 'parsup1', 'famsup1', 'supsup2', 'cowsup2', 'parsup2', 'famsup2', 'supsup3', 'cowsup3', 'parsup3', 'famsup3', 'supsup4', 'cowsup4', 'parsup4', 'famsup4', 'cogflex1', 'cogflex2', 'cogflex3', 'cogflex4', 'cogflex5', 'cogflex6', 'cogflex7', 'cogflex8', 'cogflex9', 'cogflex10', 'cogflex11', 'cogflex12', 'houswork', 'childwork', 'marstat', 'children', 'whours', 'tenure', 'position', 'education', 'gender', 'age', 'industry', 'otherindustry', 'nationality', 'residence', 'lang', 'feeltravel', 'yearstravel', 'numbertravel', 'daysknowtravel', 'meettravel', 'flytravel', 'countrytravel', 'daystrip', 'reasontrip', 'otherreasontrip', 'weekendtrip']\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 2: Inspect the Data\n",
    "\n",
    "Questions to answer:\n",
    "    1. Shape:\n",
    "        Number of rows and columns: Shape of dataset: (579, 222)\n",
    "    2. Data Types:\n",
    "        Identify numeric, categorical, and datetime columns.\n",
    "    3. Missing Values:\n",
    "        Count and percentage of missing values in each column.\n",
    "    4. Summary Statistics:\n",
    "        Get an overview of the data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (579, 222)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 579 entries, 0 to 578\n",
      "Columns: 222 entries, travfreq to weekendtrip\n",
      "dtypes: float64(17), int64(187), object(18)\n",
      "memory usage: 1004.3+ KB\n",
      "None\n",
      "         travfreq  aircrew   empl     jobsat1     jobsat2     jobsat3  \\\n",
      "count  579.000000    524.0  579.0  579.000000  579.000000  579.000000   \n",
      "mean     3.447323      2.0    1.0    4.243523    4.234888    4.217617   \n",
      "std      0.881513      0.0    0.0    0.834655    0.827778    0.772114   \n",
      "min      2.000000      2.0    1.0    1.000000    1.000000    1.000000   \n",
      "25%      3.000000      2.0    1.0    4.000000    4.000000    4.000000   \n",
      "50%      3.000000      2.0    1.0    4.000000    4.000000    4.000000   \n",
      "75%      4.000000      2.0    1.0    5.000000    5.000000    5.000000   \n",
      "max      5.000000      2.0    1.0    5.000000    5.000000    5.000000   \n",
      "\n",
      "        roleover1   roleover2   roleover3    workadj1  ...   education  \\\n",
      "count  579.000000  579.000000  579.000000  579.000000  ...  576.000000   \n",
      "mean     3.347150    3.160622    3.236615    4.314335  ...    3.229167   \n",
      "std      1.216398    1.256170    1.223037    0.785675  ...    1.029774   \n",
      "min      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
      "25%      2.000000    2.000000    2.000000    4.000000  ...    3.000000   \n",
      "50%      3.000000    3.000000    3.000000    4.000000  ...    3.000000   \n",
      "75%      4.000000    4.000000    4.000000    5.000000  ...    4.000000   \n",
      "max      5.000000    5.000000    5.000000    5.000000  ...    5.000000   \n",
      "\n",
      "           gender         age    industry  feeltravel  yearstravel  \\\n",
      "count  579.000000  579.000000  578.000000  579.000000   579.000000   \n",
      "mean     1.392055   37.970639    8.397924    1.461140     6.800518   \n",
      "std      0.488631   10.374852    3.332129    0.720289     6.201101   \n",
      "min      1.000000   18.000000    1.000000    1.000000     0.000000   \n",
      "25%      1.000000   30.000000    5.000000    1.000000     2.000000   \n",
      "50%      1.000000   35.000000    9.000000    1.000000     5.000000   \n",
      "75%      2.000000   44.000000   12.000000    2.000000    10.000000   \n",
      "max      2.000000   73.000000   13.000000    3.000000    40.000000   \n",
      "\n",
      "        flytravel    daystrip  reasontrip  weekendtrip  \n",
      "count  579.000000  577.000000  579.000000   579.000000  \n",
      "mean     1.880829    6.289428    2.804836     1.595855  \n",
      "std      0.656057    5.665543    1.699250     0.851855  \n",
      "min      1.000000    0.000000    1.000000     1.000000  \n",
      "25%      1.000000    4.000000    1.000000     1.000000  \n",
      "50%      2.000000    5.000000    2.000000     1.000000  \n",
      "75%      2.000000    7.000000    4.000000     2.000000  \n",
      "max      3.000000   90.000000    6.000000     3.000000  \n",
      "\n",
      "[8 rows x 204 columns]\n",
      "Missing Values:\n",
      " travfreq             0\n",
      "aircrew             55\n",
      "empl                 0\n",
      "jobsat1              0\n",
      "jobsat2              0\n",
      "                  ... \n",
      "countrytravel        1\n",
      "daystrip             2\n",
      "reasontrip           0\n",
      "otherreasontrip    541\n",
      "weekendtrip          0\n",
      "Length: 222, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Shape and info\n",
    "print(f\"Shape of dataset: {df.shape}\")\n",
    "print(df.info())\n",
    "\n",
    "# Summary statistics\n",
    "print(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "missing_data = df.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The actual count of missing values in the dataset, to get an estimate of which column contains the most missing values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "aircrew             55\n",
       "turnover1            1\n",
       "turnover2            2\n",
       "turnover3            3\n",
       "wneglect1            2\n",
       "wneglect2            4\n",
       "wneglect3            1\n",
       "wneglect4            2\n",
       "wneglect5            2\n",
       "wneglect6            3\n",
       "wpeopresp3           3\n",
       "wpeopresp4           2\n",
       "wpeopresp5           3\n",
       "wteams               1\n",
       "wcom                 2\n",
       "houswork             2\n",
       "childwork            7\n",
       "whours               2\n",
       "tenure              14\n",
       "education            3\n",
       "industry             1\n",
       "otherindustry      468\n",
       "nationality          5\n",
       "residence            5\n",
       "lang               108\n",
       "countrytravel        1\n",
       "daystrip             2\n",
       "otherreasontrip    541\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The actual count of missing values in the dataset, to get an estimate of which column contains the most missing values')\n",
    "\n",
    "df[df.columns[df.isnull().any()]].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentatge of missing values in the dataset, to get an estimate of which column contains the most missing values and make a decision on how to fill them\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "aircrew             9.499136\n",
       "turnover1           0.172712\n",
       "turnover2           0.345423\n",
       "turnover3           0.518135\n",
       "wneglect1           0.345423\n",
       "wneglect2           0.690846\n",
       "wneglect3           0.172712\n",
       "wneglect4           0.345423\n",
       "wneglect5           0.345423\n",
       "wneglect6           0.518135\n",
       "wpeopresp3          0.518135\n",
       "wpeopresp4          0.345423\n",
       "wpeopresp5          0.518135\n",
       "wteams              0.172712\n",
       "wcom                0.345423\n",
       "houswork            0.345423\n",
       "childwork           1.208981\n",
       "whours              0.345423\n",
       "tenure              2.417962\n",
       "education           0.518135\n",
       "industry            0.172712\n",
       "otherindustry      80.829016\n",
       "nationality         0.863558\n",
       "residence           0.863558\n",
       "lang               18.652850\n",
       "countrytravel       0.172712\n",
       "daystrip            0.345423\n",
       "otherreasontrip    93.436960\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The percentatge of missing values in the dataset, to get an estimate of which column contains the most missing values and make a decision on how to fill them')\n",
    "df[df.columns[df.isnull().any()]].isnull().sum() * 100 / df.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the result:\n",
    "1. otherreasontrip    : 93%\n",
    "2. otherindustry      : 80%\n",
    "3. lang               : 18%\n",
    "4. aircrew            : 9%\n",
    "5. tenure             : 2%\n",
    "6. childwork          : 1%\n",
    "\n",
    "Are above zero, hence the priority of dealing the columns missing values is documented.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. otherreasontrip    : 93%   need details on how to fill the null values\n",
    "2. otherindustry      : 80%   need to understand if this is important field and if that can be filled with a meaning full value\n",
    "3. lang               : 18%   need to undertand meaningful value to fill it with\n",
    "4. aircrew            : 9%    I believe this isnt priority, need confirmation\n",
    "5. tenure             : 2%    default value? or just drop?\n",
    "6. childwork          : 1%     need info on the column \n",
    "\n",
    "\n",
    "\n",
    "Info that I miss to understand :\n",
    "\n",
    "yearstravel\t\n",
    "numbertravel\t\n",
    "daysknowtravel\t\n",
    "meettravel\n",
    "daystrip\t\n",
    "reasontrip\t\n",
    "otherreasontrip\t\n",
    "weekendtrip\n",
    "\t\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to do:\n",
    "\n",
    "write a proposal\n",
    "    what do i need for this:\n",
    "    -understanding how to translate the current model to ML\n",
    "    -variables to be used\n",
    "    -interpret latent variables\n",
    "    -evaluation, y variable, x variable, ML task?\n",
    "\n",
    "Missing value filling:\n",
    "-how and which\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
